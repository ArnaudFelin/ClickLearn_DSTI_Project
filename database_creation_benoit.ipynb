{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a training database: import and load Pamguard CSV files\n",
    "\n",
    "\n",
    "(CLICKLEARN DSTI Project)\n",
    "\n",
    "The objective of this notebook is to complete Ketos *Creating Database (Extended)* notebook:\n",
    "https://docs.meridian.cs.dal.ca/ketos/tutorials/create_database/index.html\n",
    "\n",
    "Sections *1. Imports* and *2. Building annotation files* of this notebook are to be implemented at the beginning of *Chapter 2. Loading the annotations* of the original notebook. Chapter 2 describes methods to import CSV files which already match to the Ketos requirements. No major implementations were provided in Chapter 3 and following ones.\n",
    "\n",
    "This notebook provides methods to load a CSV file exported by **Pamguard software**, and convert it as Ketos annotation table, dealing with datetime and timedelta operations. Pamguard is an open source software which objective is to provide free and easy to handle tools for cetacean passive acoustic monitoring (PAM):\n",
    "https://www.pamguard.org/\n",
    "\n",
    "Two types of CSV file exported by Pamguard can be used with these methods:\n",
    "\n",
    "* **Events annotation CSV files**: quoting start and end of time ranges (several seconds long) in which clicks streams have been identified.\n",
    "* **Clicks annotation CSV files**: quoting start time of identified clicks. Click duration is about few milliseconds and has to be set in parameters (see below).\n",
    "\n",
    "The converted annotation tables will then be ready to be directly used by Ketos library (see Chapter 3 and followings).\n",
    "\n",
    "\n",
    "## Contents:\n",
    "\n",
    "[1. Imports](#section1)  \n",
    "[2. Building annotation files](#section2)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the packages\n",
    "(CLICKLEARN DSTI)\n",
    "\n",
    "We will use several modules within ketos and also the pandas package\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\groul\\anaconda3\\envs\\ketos_env\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ketos.data_handling import selection_table as sl\n",
    "import ketos.data_handling.database_interface as dbi\n",
    "from ketos.data_handling.parsing import load_audio_representation\n",
    "from ketos.audio.spectrogram import MagSpectrogram\n",
    "from ketos.data_handling.parsing import load_audio_representation\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Union\n",
    "import math\n",
    "import random\n",
    "\n",
    "# This last package is made by ClickLearn DSTI team to extract informations from a Pamguard CSV export file \n",
    "# and buid a Ketos annotation table (Pandas dataframe)\n",
    "import ketos_annotation_table as kat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions\n",
    "\n",
    "(CLICKLEARN DSTI Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color : red;\">\n",
    "TODO:\n",
    "    \n",
    "* Move following methods in Ketos_annotation_table.py when finished, then delete this chapter\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pamguard_name_to_datetime(filename:str):\n",
    "    \"\"\"Extract a datetime value from a PAMGUARD sound file name.\n",
    "\n",
    "        Args:\n",
    "            filename : str\n",
    "                PAMGUARD .wav or audio_file name\n",
    "        Returns:\n",
    "            datetime\n",
    "                Formatted datetime value (like 2019-02-24 13:15:00)\n",
    "\n",
    "        Examples\n",
    "            >>> pamguard_name_to_datetime('Click_Detector_Sperm_whale_click_detector_Clicks_20180601_010000.pgdf')\n",
    "            datetime.datetime(2018, 6, 1, 1, 0)\n",
    "            >>> pamguard_name_to_datetime('192_20180705_123056_853.wav')\n",
    "            datetime.datetime(2018, 7, 5, 12, 30, 56)\n",
    "    \"\"\"\n",
    "    # split filename from its suffix (.wav or .pgdf)\n",
    "    filename, suffix = os.path.splitext(filename)\n",
    "    # remove milliseconds from filename (occurs on Pamguard .wav filenames)\n",
    "    if \".wav\" in suffix:\n",
    "        filename = filename[:-4]\n",
    "    # returns the date part of the remaining filename as a datetime\n",
    "    return datetime.strptime(filename[-15:], '%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_dataframe(df):\n",
    "    \"\"\"Removes any white space before and after value of every cells of a dataframe.\n",
    "\n",
    "        Args:\n",
    "            df: pd.DataFrame\n",
    "        Returns:\n",
    "            df: pd.DataFrame\n",
    "    \"\"\"\n",
    "    for column in df:\n",
    "        if isinstance(df[column][0], str):\n",
    "            df[column] = df[column].str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_annotation_df_labels(annotation_df, labels_to_modify:set, valid_labels: set):\n",
    "    \"\"\"Replaces a set of labels with valid labels, in a columns named 'label' of a Pandas Annotation dataframe\n",
    "    \n",
    "        Args:\n",
    "            annotation_df: pd.DataFrame\n",
    "                Annotation table imported from Pamguard\n",
    "            labels_to_modify: set\n",
    "                set of strings\n",
    "            valid_labels: set\n",
    "                set of strings characters corresponding to every valid labels for any annotation\n",
    "\n",
    "        Returns:\n",
    "            annotation_df: pd.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    # check validity of new labels\n",
    "    unmatched_labels = set(labels_to_modify.values()) - set(valid_labels)\n",
    "    if len(unmatched_labels) != 0:\n",
    "        print('Following labels doesn\\'t match label list: ', unmatched_labels)\n",
    "    else:\n",
    "        # replace old labels by new ones\n",
    "        for old_label, new_label in labels_to_modify.items():\n",
    "            annotation_df.loc[annotation_df.label == old_label,'label'] = new_label\n",
    "    return annotation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def subsample_dataframe(df_to_subsample, train_proportion:float):\n",
    "    \"\"\"Subsample a Pandas DataFrame into 2 others, based on its indexes.\n",
    "        \n",
    "        Args:\n",
    "            df_to_subsample: pd.DataFrame\n",
    "            train_proportion: float\n",
    "                proportion (]0;1[) of indexes to subsample in the dataset, in order to build the train dataset\n",
    "    \n",
    "        Returns: tuple with 2 dataframes:\n",
    "            [0] train subsample \n",
    "            [1] test subsamples\n",
    "    \"\"\"\n",
    "    length = len(df_to_subsample)\n",
    "    nb_train_rows = math.ceil(train_proportion*length)\n",
    "    #create a sequence corresponding to df indexes to subsample \n",
    "    sequence = set(range(length))\n",
    "    train_indexes = random.sample(sequence, nb_train_rows)\n",
    "    test_indexes = list(sequence - set(train_indexes))\n",
    "    return df_to_subsample.iloc[train_indexes], df_to_subsample.iloc[test_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pamguard_annotations_csv_to_df(annotation_csv_path:str, annotation_type:str = 'events', events_subsampling_option:int = 2, click_duration:float = 2):\n",
    "    \"\"\"Convert a Pamguard CSV annotation file into a Ketos annotation table (non standardized). \n",
    "        This method contains several identical \"if\" statements, that were not gathered for more readability.\n",
    "\n",
    "        Args:\n",
    "            annotation_csv_path: str\n",
    "                complete path of the CSV file. CSV separator must be ','\n",
    "            annotation_type: str\n",
    "                2 values are possible: 'events' (default value, for Events annotation CSV files) or 'clicks' (for Clicks annotation CSV files)\n",
    "            events_subsampling_option: int\n",
    "                Subsampling is optional but highly recommended to avoid unsure detections. \n",
    "                Several subsamplings of annotations_csv_df are possible, \n",
    "                from the less to the most selective option:\n",
    "                - 0: no subsampling\n",
    "                - 1: subsample excluding all commented detections in 'comment' column \n",
    "                    (comments always refer to unsure detections), \n",
    "                    then including 'definite' ('DLD') and 'probable' ('DLP') dolphin click detections as well\n",
    "                - 2 (default value): subsample excluding all commented detections in 'comment' column \n",
    "                    (comments always refer to unsure detections), \n",
    "                    then including only 'definite' dolphin click detections ('DLD')\n",
    "                N.B.: Clicks annotation CSV files are only based on (uncommented) definite dolphin click \n",
    "                detections ('DLD'), so it is unnecessary to subsample them regarding to any comment or label. \n",
    "            click_duration: float\n",
    "               click duration in milliseconds\n",
    "               \n",
    "        Returns:\n",
    "            annotations_df: pd.DataFrame\n",
    "                Ketos annotation table (non standardized)\n",
    "    \"\"\"\n",
    "    # import CSV in a dataframe\n",
    "    annotations_df = pd.read_csv(annotation_csv_path, sep=\",\")\n",
    "\n",
    "    # Remove all whitespaces from string typed series of the dataframe \n",
    "    annotations_df = strip_dataframe(annotations_df)\n",
    "    \n",
    "    # SUBSAMPLING (SPECIFIC TO EVENT ANNOTATION DF, with option 2 > 1 > 0, check docstring):\n",
    "    if annotation_type == 'events':\n",
    "        if events_subsampling_option == 2:\n",
    "            annotations_df = annotations_df.loc[((annotations_df.comment.isna()) \n",
    "                                                 & (annotations_df.eventType == 'DLD')),]\n",
    "        if events_subsampling_option == 1:\n",
    "            annotations_df = annotations_df.loc[(annotations_df.comment.isna()),]    \n",
    "    \n",
    "    # DATETIME AND LABELS REWORKING:\n",
    "    if annotation_type == 'events':\n",
    "        \n",
    "        # updating pd.Series type from string to datetime\n",
    "        annotations_df.EventStart = pd.to_datetime(annotations_df.EventStart, format = '%Y-%m-%d %H:%M:%S.%f')\n",
    "        \n",
    "        # To complete Eventstart series, EventStartMilliseconds must be added to Clickstart values as a pd.Timedelta\n",
    "        EventStartMilliseconds_events = pd.Series([pd.Timedelta(val, unit = 'milliseconds') for val in annotations_df.EventStartMilliseconds])\n",
    "        # reset index allows to do arithmetic operators between annotations_df and EventStartMilliseconds_events\n",
    "        annotations_df = annotations_df.reset_index()\n",
    "        annotations_df.EventEnd = pd.to_datetime(annotations_df.EventEnd, format = '%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "        # updating all datetime values (beginning & end of events) into seconds from the beginning of the recording\n",
    "        # for this, convert first file name into pandas Timedelta format\n",
    "        annotations_df.EventStart = (annotations_df.EventStart \n",
    "                                     + EventStartMilliseconds_events\n",
    "                                     - annotations_df.WAVFile.apply(pamguard_name_to_datetime)).apply(pd.Timedelta.total_seconds)\n",
    "        annotations_df.EventEnd = (annotations_df.EventEnd \n",
    "                                   - annotations_df.WAVFile.apply(pamguard_name_to_datetime)).apply(pd.Timedelta.total_seconds)\n",
    "        \n",
    "    if annotation_type == 'clicks':\n",
    "        \n",
    "        # updating pd.Series type from string to datetime\n",
    "        annotations_df.Clickstart = pd.to_datetime(annotations_df.Clickstart, format = '%Y-%m-%d %H:%M:%S.%f')\n",
    "        \n",
    "        # To complete Clickstart series, UTCMilliseconds must be added to Clickstart values as a pd.Timedelta\n",
    "        UTCMilliseconds_clicks = pd.Series([pd.Timedelta(val, unit = 'milliseconds') for val in annotations_df.UTCMilliseconds])\n",
    "        \n",
    "        # Converts click_duration into Timedelta format\n",
    "        click_duration = pd.Timedelta(click_duration, unit = 'milliseconds')\n",
    "        \n",
    "        # Compute Clickend series thanks to click duration then add it in the dataframe\n",
    "        annotations_df['Clickend'] = pd.Series(annotations_df.Clickstart + click_duration)\n",
    "        \n",
    "        # add a label for each click detection\n",
    "        annotations_df['label'] = label\n",
    "\n",
    "        # updating all datetime values (beginning & end of events) into seconds from the beginning of the recording\n",
    "        # for this, convert first file name into pandas Timedelta format\n",
    "        annotations_df.Clickstart = (annotations_df.Clickstart \n",
    "                                     + UTCMilliseconds_clicks\n",
    "                                     - annotations_df.BinaryFile.apply(pamguard_name_to_datetime)).apply(pd.Timedelta.total_seconds)\n",
    "        annotations_df.Clickend = (annotations_df.Clickend \n",
    "                                           + UTCMilliseconds_clicks \n",
    "                                           - annotations_df.BinaryFile.apply(pamguard_name_to_datetime)).apply(pd.Timedelta.total_seconds)\n",
    "\n",
    "    # COLUMNS REWORKING:\n",
    "    if annotation_type == 'events':\n",
    "        # select only columns required in Ketos annotation table\n",
    "        annotations_df = annotations_df.loc[:,('Id', 'EventStart', 'EventEnd', 'eventType', 'WAVFile', 'comment')]\n",
    "        # update column names to fit Ketos annotation table format\n",
    "        annotations_df = annotations_df.rename(\n",
    "            columns = {'EventStart':'start', 'EventEnd':'end', 'eventType':'label', 'WAVFile':'filename'})\n",
    "    \n",
    "    if annotation_type == 'clicks':\n",
    "        # select only columns required in Ketos annotation table\n",
    "        annotations_df = annotations_df.loc[:,('Id', 'Clickstart', 'Clickend', 'label', 'BinaryFile')]\n",
    "        # update column names to fit Ketos annotation table format\n",
    "        annotations_df = annotations_df.rename(\n",
    "            columns = {'Clickstart':'start', 'Clickend':'end', 'BinaryFile':'filename'})\n",
    "\n",
    "    # Update pamguard default labels with labels used by Ketos\n",
    "    annotations_df = update_annotation_df_labels(annotations_df, labels_to_modify, valid_labels)\n",
    "    \n",
    "    # Check start and end values of events annotation df\n",
    "    if annotation_type == 'events':\n",
    "        check_pamguard_annotation_df(annotations_df)\n",
    "        \n",
    "\n",
    "    return annotations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pamguard_annotation_df(df):\n",
    "    \"\"\"Check annotations from a CSV file extracted from Pamguard software. Uses check_annotation in a loop.\n",
    "    \n",
    "        Args:\n",
    "            df: Pandas DataFrame\n",
    "                Pamguard annotation DataFrame converted by the pamguard_annotations_csv_to_df() method.\n",
    "        \n",
    "        Returns: \n",
    "            errors: list\n",
    "                List of errors containing each incorrect annotation\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    for index, row in df.iterrows():\n",
    "        check_annotation_time(row.start, row.end, row.Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_annotation_time(start:str, end:str, index = 0):\n",
    "    \"\"\"Check time validity of 1 annotation (or 1 row of an annotation table): end value must be subsequent to start value.\n",
    "        Print error messages.\n",
    "        \n",
    "        Args:\n",
    "            start: str\n",
    "                Start time for the annotation, in seconds from the beginning of the file\n",
    "            end: str\n",
    "                End time for the annotation, in seconds from the beginning of the file\n",
    "            index: int\n",
    "                Row index (DataFrames)\n",
    "        \n",
    "        Returns: \n",
    "            str\n",
    "               String, containing index and details about the incorrect annotation\n",
    "    \n",
    "    \"\"\"\n",
    "    if start > end: \n",
    "        return f'Id {index}: end value ({end}) is prior to start value ({start})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hand input methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hand_input(start: Union[int, float, str], end: Union[int, float, str], label: str, valid_labels: set):\n",
    "    \"\"\"Check validity of an annotation added by hand. This checking is used before appending it in the annotation \n",
    "        dataframe with append_hand_input_to_annotations() method.     \n",
    "        Each annotation must pass following tests before being considered as correct :\n",
    "        - start and end types must be integer, float or string\n",
    "        - label must be included in kat.labels list\n",
    "        \n",
    "        Args:\n",
    "            start: int, float, str\n",
    "                Start time for the annotation, in seconds from the beginning of the file\n",
    "            end: int, float, str\n",
    "                End time for the annotation, in seconds from the beginning of the file\n",
    "            label: str\n",
    "                Label of the annotation\n",
    "            valid_labels: set\n",
    "                Set of every valid labels (strings characters) for any annotation \n",
    "        \n",
    "        Returns: \n",
    "            errors: list\n",
    "                List of errors (string characters) describing each incorrect annotation.\n",
    "    \"\"\"\n",
    "    #initialize error list to be returned\n",
    "    errors = []\n",
    "\n",
    "    #check validity of start & end values \n",
    "    try:\n",
    "        float(start)\n",
    "    except:\n",
    "        errors += ['start value is not int, float or string']\n",
    "    try:\n",
    "        float(end)\n",
    "    except:\n",
    "        errors += ['end value is not int, float or string']\n",
    "    if start > end: \n",
    "        errors += ['end value is prior to start value']\n",
    "    \n",
    "    #test if label is included in kat.labels list\n",
    "    if label not in valid_labels:\n",
    "        errors += ['label is not included in valid labels list']\n",
    "        \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overlap_errors(annotation_to_add, annotation_df):\n",
    "    \"\"\"Check if a hand mande annotation start or end value overlaps one or several annotations of a Pandas DataFrame.\n",
    "        \n",
    "        Args:\n",
    "            annotation_to_add: Pandas Series\n",
    "                Annotation to add in the annotation table\n",
    "            annotation_df: Pandas DataFrame\n",
    "                Ketos annotation table\n",
    "        \n",
    "        Returns: \n",
    "            errors: list\n",
    "                List of errors (string characters) describing each incorrect annotation.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    for index, row in annotation_df.iterrows():\n",
    "        if (row.start <= annotation_to_add.iloc[0]['start'] <= row.end):\n",
    "            errors += [f'start value overlap at index {index}']\n",
    "        if (row.start <= annotation_to_add.iloc[0]['end'] <= row.end):\n",
    "            errors += [f'end value overlap at index {index}']\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def append_hand_input_to_annotations(annotation_dataframe, filename:str, start:float, end:float, label:str, valid_labels:set):\n",
    "    \"\"\"Appends a custom annotation to a Ketos annotation table. If any error occurs, print the error description. \n",
    "        \n",
    "        Args:\n",
    "            annotation_dataframe: Pandas DataFrame\n",
    "                Ketos annotation table\n",
    "            filename: str\n",
    "                Name of the audio file\n",
    "            start:float\n",
    "                Start time for the annotation, in seconds from the beginning of the file\n",
    "            end: float\n",
    "                End time for the annotation, in seconds from the beginning of the file\n",
    "            label: str\n",
    "                Label of the annotation\n",
    "            valid_labels: set\n",
    "                Set of every valid labels (strings characters) for any annotation \n",
    "        \n",
    "        Returns: \n",
    "            annotation_dataframe: Pandas DataFrame\n",
    "                Updated Ketos annotation table with the new annotation \n",
    "    \"\"\"\n",
    "    errors = check_hand_input(start, end, label, valid_labels)\n",
    "    \n",
    "    if not errors:\n",
    "        Id = annotation_dataframe.iloc[-1]['Id'] + 1\n",
    "        annotation_temp = pd.DataFrame([[Id , round(float(start),4), round(float(end),4), label, filename]], \n",
    "                                       columns = ['Id', 'start', 'end', 'label', 'filename']) \n",
    "        errors = check_overlap_errors(annotation_temp, annotation_dataframe)\n",
    "        if not errors:\n",
    "            #append temp to annotation DF \n",
    "            annotation_dataframe = annotation_dataframe.append(annotation_temp, ignore_index = True)\n",
    "    if errors:\n",
    "        print('Following errors occured:')\n",
    "        for er in errors:\n",
    "            print(er)\n",
    "    return annotation_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "## 2. Building annotation files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section describes methods to create or modify an annotation table. New methods are added to the original documentation to import Pamguard CSV files and to add annotations by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting parameters to build the Annotation table \n",
    "(CLICKLEARN DSTI Project)\n",
    "\n",
    "\n",
    "This part contains all required settings to build annotation dataframes:\n",
    "* Audio files path (where all audio files are stored)\n",
    "* Annotation file path, where: \n",
    "    + CSV fils are stored\n",
    "    + Annotation tables **will be** stored\n",
    "* Click duration in milliseconds (for Click annotation CSV files)\n",
    "* Set of valid labels to be used (all labels from CSV file that are not matching this set will be stored in an error log file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH SETTINGS\n",
    "# Annotation CSV file folder path (MAC)\n",
    "# annotations_folder_path ='/Users/benoitmialet/Ketos/tutorials_create_database_database_creation_tutorial'\n",
    "# Annotation CSV file folder path (W10)\n",
    "annotations_folder_path = (r'D:\\SYSTEL\\Ketos\\tutorials_create_database_database_creation_tutorial')\n",
    "# Annotation CSV file name\n",
    "csv_events_name = 'UBISEA_acoustic_detections_samples_events_completed.csv' # WAVFile column was manually added in this file \n",
    "csv_clicks_name = 'UBISEA_acoustic_detections_samples_clicks.csv'\n",
    "\n",
    "# PATH BUILDING\n",
    "csv_folder_path = annotations_folder_path\n",
    "csv_events_path = os.path.join(csv_folder_path,csv_events_name)\n",
    "csv_clicks_path = os.path.join(csv_folder_path,csv_clicks_name)\n",
    "\n",
    "# CLICK ANNOTATION SETTINGS \n",
    "# set click duration (milliseconds) for the dataframe\n",
    "clickDuration = pd.Timedelta(2.5, unit = 'milliseconds')\n",
    "# set label corresponding to a click detection\n",
    "label = 'DLD'\n",
    "\n",
    "# LABELS SETTINGS\n",
    "# valid labels for annotation dataframes, must be a list:\n",
    "valid_labels = {'dolphin_click','other'}\n",
    "# annotation dataframe labels to replace by valid labels (must be included in valid labels)\n",
    "labels_to_modify = {'DLP':'dolphin_click','DLD':'dolphin_click'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Option 1: Importing a Pamguard CSV file\n",
    "(CLICKLEARN DSTI Project)\n",
    "\n",
    "CSV files exported by Pamguard software can be converted into a Ketos annotation table.\n",
    "Export must be done with **default options and variable names**. 2 CSV file types are possible to import, with 'pamguard_annotations_csv_to_df' method : \n",
    "* **\"events\"**: in these files, annotations correspond to groups of clicks of several seconds.\n",
    "    + Between EventStart and EventEnd datetime values, a various number of clicks (nClicks) are included.\n",
    "    + use method with parameters annotation_type == 'events' and  events_subsampling_option (report to the method's docstring)\n",
    "    + In the CSV files, columns **in bold** are required and must have **exactely the same headers** as followig: \n",
    "![Pamguard event csv](capture_PAMGUARD_event_csv.png)\n",
    "\n",
    "\n",
    "* **\"clicks\"**: in these files, annotations correspond to beginning of clicks ('Clickstart', in datetime format). 'Clickend' values end are automatically computed by setting a click duration ('click_duration') in milliseconds among parameters. \n",
    "    Clickend will simply be the result of Clickstart + click_duration datetimes. In the CSV files, columns **in bold** are required and must have **exactely the same headers** as followig:\n",
    "![Pamguard click csv](capture_PAMGUARD_click_csv.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert CSV annotation files into Ketos annotation tables\n",
    "pamguard_annotations_csv_to_df() and pamguard_annotations_csv_to_df() methods are built with a set of other methods to import and convert a Pamguard CSV file into a Ketos annotation Table. The returned data frame are not yet standardized and thus can be modified or processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_annot_df = pamguard_annotations_csv_to_df(csv_events_path, 'events', events_subsampling_option = 2)\n",
    "clicks_annot_df = pamguard_annotations_csv_to_df(csv_clicks_path, 'clicks', click_duration = 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>465</td>\n",
       "      <td>25968.249</td>\n",
       "      <td>26012.0</td>\n",
       "      <td>dolphin_click</td>\n",
       "      <td>192_20180601_010000_458.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>466</td>\n",
       "      <td>26699.235</td>\n",
       "      <td>26726.0</td>\n",
       "      <td>dolphin_click</td>\n",
       "      <td>192_20180601_010000_458.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>469</td>\n",
       "      <td>66225.582</td>\n",
       "      <td>66262.0</td>\n",
       "      <td>dolphin_click</td>\n",
       "      <td>192_20180601_010000_458.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>473</td>\n",
       "      <td>67330.013</td>\n",
       "      <td>67353.0</td>\n",
       "      <td>dolphin_click</td>\n",
       "      <td>192_20180601_010000_458.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>474</td>\n",
       "      <td>67522.346</td>\n",
       "      <td>67577.0</td>\n",
       "      <td>dolphin_click</td>\n",
       "      <td>192_20180601_010000_458.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id      start      end          label                     filename comment\n",
       "0  465  25968.249  26012.0  dolphin_click  192_20180601_010000_458.wav     NaN\n",
       "1  466  26699.235  26726.0  dolphin_click  192_20180601_010000_458.wav     NaN\n",
       "2  469  66225.582  66262.0  dolphin_click  192_20180601_010000_458.wav     NaN\n",
       "3  473  67330.013  67353.0  dolphin_click  192_20180601_010000_458.wav     NaN\n",
       "4  474  67522.346  67577.0  dolphin_click  192_20180601_010000_458.wav     NaN"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_annot_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>465</td>\n",
       "      <td>25968.249</td>\n",
       "      <td>26012.0</td>\n",
       "      <td>dolphin_click</td>\n",
       "      <td>192_20180601_010000_458.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>466</td>\n",
       "      <td>26699.235</td>\n",
       "      <td>26726.0</td>\n",
       "      <td>dolphin_click</td>\n",
       "      <td>192_20180601_010000_458.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>469</td>\n",
       "      <td>66225.582</td>\n",
       "      <td>66262.0</td>\n",
       "      <td>dolphin_click</td>\n",
       "      <td>192_20180601_010000_458.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>473</td>\n",
       "      <td>67330.013</td>\n",
       "      <td>67353.0</td>\n",
       "      <td>dolphin_click</td>\n",
       "      <td>192_20180601_010000_458.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>474</td>\n",
       "      <td>67522.346</td>\n",
       "      <td>67577.0</td>\n",
       "      <td>dolphin_click</td>\n",
       "      <td>192_20180601_010000_458.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id      start      end          label                     filename comment\n",
       "0  465  25968.249  26012.0  dolphin_click  192_20180601_010000_458.wav     NaN\n",
       "1  466  26699.235  26726.0  dolphin_click  192_20180601_010000_458.wav     NaN\n",
       "2  469  66225.582  66262.0  dolphin_click  192_20180601_010000_458.wav     NaN\n",
       "3  473  67330.013  67353.0  dolphin_click  192_20180601_010000_458.wav     NaN\n",
       "4  474  67522.346  67577.0  dolphin_click  192_20180601_010000_458.wav     NaN"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_annot_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize Ketos annotation tables\n",
    "ketos.data_handling.selection_table.standardize() is the original method to standardize an annotation table for Ketos once it is built. ketos.data_handling.selection_table.is_standardized() checks if this standardization is completed or return error description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if both events and clicks files are in standardized format:\n",
      " True \n",
      " True\n"
     ]
    }
   ],
   "source": [
    "# standardize all annotation tables\n",
    "std_events_annot_df = sl.standardize(table = events_annot_df, signal_labels = valid_labels, trim_table=False)\n",
    "std_clicks_annot_df = sl.standardize(table = clicks_annot_df, signal_labels = valid_labels, trim_table=False)\n",
    "\n",
    "\n",
    "print('check if both events and clicks files are in standardized format:\\n', \n",
    "     sl.is_standardized(std_events_annot_df), '\\n',\n",
    "     sl.is_standardized(std_clicks_annot_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting into 2 random subsamples (annotation_train / annotation_test)\n",
    "(CLICKLEARN DSTI Project)\n",
    "subsample_dataframe() method is created to split the annotation table into 2 subsamples:\n",
    "* Train annotation table (Ketos will use it to create the training dataset)\n",
    "* Test annotation table (Ketos will use it to create the testing dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function subsample_dataframe in module __main__:\n",
      "\n",
      "subsample_dataframe(df_to_subsample, train_proportion: float)\n",
      "    Subsample a Pandas DataFrame into 2 others, based on its indexes.\n",
      "    \n",
      "    Args:\n",
      "        df_to_subsample: pd.DataFrame\n",
      "        train_proportion: float\n",
      "            proportion (]0;1[) of indexes to subsample in the dataset, in order to build the train dataset\n",
      "    \n",
      "    Returns: tuple with 2 dataframes:\n",
      "        - [0] train subsample \n",
      "        - [1] test subsamples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(subsample_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_annot_train_events = subsample_dataframe(std_events_annot_df, 0.7)[0]\n",
    "std_annot_test_events = subsample_dataframe(std_events_annot_df, 0.7)[1]\n",
    "\n",
    "std_annot_train_clicks  = subsample_dataframe(std_clicks_annot_df, 0.7)[0]\n",
    "std_annot_test_clicks = subsample_dataframe(std_clicks_annot_df, 0.7)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th>annot_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192_20180603_000000_458.wav</th>\n",
       "      <th>1</th>\n",
       "      <td>527</td>\n",
       "      <td>5258.439</td>\n",
       "      <td>5269.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">192_20180601_010000_458.wav</th>\n",
       "      <th>21</th>\n",
       "      <td>501</td>\n",
       "      <td>73691.091</td>\n",
       "      <td>73703.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>483</td>\n",
       "      <td>72607.571</td>\n",
       "      <td>72620.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>496</td>\n",
       "      <td>73415.745</td>\n",
       "      <td>73438.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>478</td>\n",
       "      <td>71702.295</td>\n",
       "      <td>71713.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Id      start      end  label comment\n",
       "filename                    annot_id                                        \n",
       "192_20180603_000000_458.wav 1         527   5258.439   5269.0      2     NaN\n",
       "192_20180601_010000_458.wav 21        501  73691.091  73703.0      2     NaN\n",
       "                            9         483  72607.571  72620.0      2     NaN\n",
       "                            18        496  73415.745  73438.0      2     NaN\n",
       "                            6         478  71702.295  71713.0      2     NaN"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_annot_train_events.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th>annot_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Click_Detector_Sperm_whale_click_detector_Clicks_20180601_190000.pgdf</th>\n",
       "      <th>525</th>\n",
       "      <td>178620</td>\n",
       "      <td>2239.421</td>\n",
       "      <td>2239.4235</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Click_Detector_Sperm_whale_click_detector_Clicks_20180601_230000.pgdf</th>\n",
       "      <th>91</th>\n",
       "      <td>181713</td>\n",
       "      <td>362.053</td>\n",
       "      <td>362.0555</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Click_Detector_Sperm_whale_click_detector_Clicks_20180603_000000.pgdf</th>\n",
       "      <th>13</th>\n",
       "      <td>182027</td>\n",
       "      <td>1381.822</td>\n",
       "      <td>1381.8245</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Click_Detector_Sperm_whale_click_detector_Clicks_20180601_190000.pgdf</th>\n",
       "      <th>503</th>\n",
       "      <td>182408</td>\n",
       "      <td>2234.209</td>\n",
       "      <td>2234.2115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Click_Detector_Sperm_whale_click_detector_Clicks_20180601_210000.pgdf</th>\n",
       "      <th>1340</th>\n",
       "      <td>180233</td>\n",
       "      <td>1459.994</td>\n",
       "      <td>1459.9965</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 Id     start  \\\n",
       "filename                                           annot_id                     \n",
       "Click_Detector_Sperm_whale_click_detector_Click... 525       178620  2239.421   \n",
       "Click_Detector_Sperm_whale_click_detector_Click... 91        181713   362.053   \n",
       "Click_Detector_Sperm_whale_click_detector_Click... 13        182027  1381.822   \n",
       "Click_Detector_Sperm_whale_click_detector_Click... 503       182408  2234.209   \n",
       "Click_Detector_Sperm_whale_click_detector_Click... 1340      180233  1459.994   \n",
       "\n",
       "                                                                   end  label  \n",
       "filename                                           annot_id                    \n",
       "Click_Detector_Sperm_whale_click_detector_Click... 525       2239.4235      2  \n",
       "Click_Detector_Sperm_whale_click_detector_Click... 91         362.0555      2  \n",
       "Click_Detector_Sperm_whale_click_detector_Click... 13        1381.8245      2  \n",
       "Click_Detector_Sperm_whale_click_detector_Click... 503       2234.2115      2  \n",
       "Click_Detector_Sperm_whale_click_detector_Click... 1340      1459.9965      2  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_annot_train_clicks.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The train and test files are now ready to be used in step *5. Creating segments of uniform length* and following ones from the original Notebook.**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Option 2: adding annotations by hand (not likely to be used)\n",
    "(CLICKLEARN DSTI Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part allows to add custom annotation by hand to a Ketos annotation table.\n",
    "\n",
    "If used on a **standardized** Ketos annotation table, numerical labels must be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Report each annotation here, and then run next cell to append the annotation into the dataframe:\n",
    "\n",
    "*    **start**: start time for the annotation, in seconds from the beginning of the file\n",
    "*    **end**: end time for the annotation, in seconds from the beginning of the file\n",
    "*    **label**: label for the annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type annotation details here\n",
    "\n",
    "annotations_df = events_annot_df\n",
    "filename = '192_20180601_010000_458.wav'\n",
    "start = 527.55  #in seconds\n",
    "end = 528.32    #in seconds\n",
    "label = 'other' #annotation label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>521</td>\n",
       "      <td>10157.910</td>\n",
       "      <td>10180.00</td>\n",
       "      <td>dolphin_click</td>\n",
       "      <td>192_20180602_000000_458.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>522</td>\n",
       "      <td>1378.201</td>\n",
       "      <td>1390.00</td>\n",
       "      <td>dolphin_click</td>\n",
       "      <td>192_20180603_000000_458.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>527</td>\n",
       "      <td>5258.439</td>\n",
       "      <td>5269.00</td>\n",
       "      <td>dolphin_click</td>\n",
       "      <td>192_20180603_000000_458.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>528</td>\n",
       "      <td>5660.552</td>\n",
       "      <td>5672.00</td>\n",
       "      <td>dolphin_click</td>\n",
       "      <td>192_20180603_000000_458.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>529</td>\n",
       "      <td>527.550</td>\n",
       "      <td>528.32</td>\n",
       "      <td>other</td>\n",
       "      <td>192_20180601_010000_458.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      start       end          label                     filename  \\\n",
       "31  521  10157.910  10180.00  dolphin_click  192_20180602_000000_458.wav   \n",
       "32  522   1378.201   1390.00  dolphin_click  192_20180603_000000_458.wav   \n",
       "33  527   5258.439   5269.00  dolphin_click  192_20180603_000000_458.wav   \n",
       "34  528   5660.552   5672.00  dolphin_click  192_20180603_000000_458.wav   \n",
       "35  529    527.550    528.32          other  192_20180601_010000_458.wav   \n",
       "\n",
       "   comment  \n",
       "31     NaN  \n",
       "32     NaN  \n",
       "33     NaN  \n",
       "34     NaN  \n",
       "35     NaN  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append the annotation to an annotation dataframe\n",
    "\n",
    "annotations_df = append_hand_input_to_annotations(annotations_df, filename, start, end, label, valid_labels)\n",
    "annotations_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Option 3: Importing a CSV file already formatted for Ketos\n",
    "(Text from original Notebook)\n",
    "\n",
    "Our annotations are saved in two `.csv` files (with values separated by `;`): `annotations_train.csv` and `annotations_test.csv`, which we will use to create the training and test datasets respectively. These files can also be found within the `.zip` file at the top of the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annot_train_path = os.path.join(*annotations_folder_path.split('\\\\'),\"annotations_train.csv\")\n",
    "annot_train = pd.read_csv(annot_train_path, sep = \",\")\n",
    "annot_test_path = os.path.join(*annotations_folder_path.split('\\\\'),\"annotations_test.csv\")\n",
    "annot_test = pd.read_csv(annot_test_path, sep = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect our annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **annot_train** dataframe contains 1000 rows and the **annot_test** 500.\n",
    "The columns indicate:\n",
    "\n",
    "**start:** start time for the annotation, in seconds from the beginning of the file  \n",
    "**end:** end time for the annotation, in seconds from the beginning of the file   \n",
    "**label:** label for the annotation (in our case, all annotated signals are 'upcalls', but the origincal DCLDE2013 dataset also had 'gunshots')  \n",
    "**sound_file:** name of the audio file  \n",
    "**datetime:** a timestamp for the beginning of the file (UTC)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Starting from here, following text is taken from the orginial Notebook, with no major implementation from ClickLearn DSTI project team. \n",
    "Only some line of codes which are specific to the project needs were added.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Putting the annotations in the Ketos format (to skip with Pamguard CSV importation)\n",
    "\n",
    "\n",
    "Let's check if our annotations follow the Ketos standard.\n",
    "\n",
    "If that's the case, the function ```sl.is_standardized``` will return ```True```. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl.is_standardized(annot_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the *verbose* argument to ```False``` will not show the example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl.is_standardized(annot_test, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither of our annotations are in the format ketos expects. But we can use the ```sl.standardize``` function to convert to the specified format.\n",
    "\n",
    "The *annot_id* column is created automatically by the ```sl.standardize``` function. From the remaining required columns indicated in the example above, we already have *start*, *end* and *label*. Our *sound_file* column needs to be renamed to *filename*, so we will need to provide a dictionary to specify that. \n",
    "\n",
    "We have one extra column, *datetime*, that we don't really need to keep, so we'll set ```trim_table=True```, which will discard any columns that are not required by the standardized.\n",
    "\n",
    "If we wanted to keep the datetime (or any other columns), we would just set ```trim_table=False```. One situation in which you might want to do that is if you need this information to split a dataset into train/test or train/validation/test, because then you can sort all your annotations by time and make sure the training set does not overlap with the validation/test. But in our case, the annotations are already split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_to_ketos_annot_std = {'sound_file': 'filename'} \n",
    "std_annot_train = sl.standardize(table=annot_train, signal_labels=[\"upcall\"], mapper=map_to_ketos_annot_std, trim_table=True)\n",
    "std_annot_test = sl.standardize(table=annot_test, signal_labels=[\"upcall\"], mapper=map_to_ketos_annot_std, trim_table=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at our standardized tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the 'label' column now encodes 'upcall' as ones (1), as the ketos format uses integers to represent labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creating segments of uniform length\n",
    "\n",
    "If you look back at our `` std_annot_train`` and ```std_annot_test``` you'll notice that annotations have a variety of lengths, since they mark the beginning and end of an upcall and these have variable durations. For our purposes, we want each signal in the database to be represented as spectrograms, all of same length. Each spectrogram will be labelled as containing an upcall or not. \n",
    "\n",
    "The ```sl.select``` function in ketos can help us to do just that: for each annotated upcall, it will select a portion of the recording surrounding it. It takes a standardized annotatoin table as input and lets you specify the length of the output segments. We'll use 3 seconds, as it is enough to encompass most upcalls.\n",
    "\n",
    "Our standardized tables only contain annotated upcalls. Later we will also want some examples of segments that only contain background noise, but for now we'll just create the uniform upcall segments, which we'll call 'positives'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(CLICKLEARN DSTI Project add:)\n",
    "* **length** (seconds): uniform length of a segment\n",
    "* **step** (seconds): shift between 2 segments (no shift if length == step)\n",
    "* **min_overlap** (proportion): if a segment crosses the start or the end of annotation, \n",
    "    proportion of its length that is allowed to cross (1 means no cross allowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicklearn\n",
    "positives_train_events = sl.select(annotations=std_annot_train_events, length=0.5, step=0.5, min_overlap=1, center=False, discard_long=False, keep_id=False)\n",
    "positives_test_events = sl.select(annotations=std_annot_test_events, length=0.5, step=0.5, min_overlap=1, center=False, discard_long=False, keep_id=False)\n",
    "\n",
    "positives_train_clicks = sl.select(annotations=std_annot_train_clicks, length=0.0025, step=0.0025, min_overlap=1, center=False, discard_long=False, keep_id=False)\n",
    "positives_test_clicks = sl.select(annotations=std_annot_test_clicks, length=0.0025, step=0.0025, min_overlap=1, center=False, discard_long=False, keep_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ketos documentation\n",
    "positives_train = sl.select(annotations=std_annot_train, length=3.0)\n",
    "positives_test = sl.select(annotations=std_annot_test, length=3.0, step=0.0, center=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Have a look at the results and notice how each entry is now 3.0 seconds long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section5></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Augmenting the data\n",
    "\n",
    "Data augmentation is a set of tecnhiques used in machine learning to increase the data available to train models. There are many different techniques that can be used. The ```sl.select``` function we just used offers a simple way to augment the data while you are creating the uniform selections. It creates segments that are longer than the annotated signals and then shifts the start and end of those segments, resulting in multiple segments with the same annotated signal (our upcalls) positioned at different times. This is a very safe technique, as it is not altering the original signal, but it can already help to increase the amount of data available. It also helps to present a larger variety of contexts in which the upcall can appear.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll augment the training portion of our annotations by using two additional arguments. The ``step`` specifies how much the signal will be shifted (in seconds). Smaller values will produce more augmented selections, but they will be more similar to the previous selection. The ```min_overlap``` argument specifies the fraction of the augmented signal that needs to overlap the original annotation in order for it to be included in the augmented selections table. A value of 1.0 means 100%, this is, the new annotation will only be included if the entire upcall falls within the stablished interval. Lower values will result in segments that only contain part of the original upcall. We'll set this value to 0.5, meaning that some of our augmented segments might have as little as half of the original call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_train = sl.select(annotations=std_annot_train, length=3.0, step=0.5, min_overlap=0.5, center=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that now our ``positives_train`` tables has almost 3x more rows than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section6></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Including background noise\n",
    "\n",
    "Now that we have the positive instances that we need to create our database, we need to include some examples of the negative class, or instances without upcalls.\n",
    "\n",
    "The ```sl.create_rndm_backgr_selections``` is ideal for our situation. It takes a standardized ketos table describing all sections of the recordings that contain annotations and takes samples from the non-annotaded portions of the files, assuming everything that is not annotated can be used as a 'background' category.\n",
    "\n",
    "**Note**:\n",
    "You might find yourself in a different scenario. For example, your annotations might already include a 'background' class or you might have annoted different classes of sounds and you only want to use a few of them. In any case, ketos provides a variety of other functions that are helpful in different scenarios. Have a look at the documentation for more details. Specially the ```selection_table``` module.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/benoitmialet/Ketos/tutorials_create_database_database_creation_tutorial'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_durations_train = sl.file_duration_table('data/train')\n",
    "annotations_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "sl.create_rndm_backgr_selections(std_annot_test, len(std_annot_test), 12, annotations=None, no_overlap=False, trim_table=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```sl.create_rndm_backgr_selections``` also needs the duration of each file, which we can generate using the ```sl.file_duration``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_durations_train = sl.file_duration_table('data/train')\n",
    "file_durations_test = sl.file_duration_table('data/test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_durations_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the file durations, we can generate our table of negative segments. We'll specify the same length (3.0 seconds). The ```num``` argument specifies the number of background segments we would like to generate. Let's make this number equal to the number of positive examples in each dataset (```len(positive_train)``` and ``` len(positive_test)```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_train=sl.create_rndm_backgr_selections(annotations=std_annot_train, files=file_durations_train, length=3.0, num=len(positives_train), trim_table=True)\n",
    "negatives_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_test=sl.create_rndm_backgr_selections(annotations=std_annot_train, files=file_durations_test, length=3.0, num=len(positives_test), trim_table=True)\n",
    "negatives_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we have it! Now we'll just put the ```positives_train``` and ```negatives_train``` together and do the same to the test tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selections_train = positives_train.append(negatives_train, sort=False)\n",
    "selections_test = positives_test.append(negatives_test, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selections_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selections_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have defined *which* audio segments we want in our database: a little over 5500 in the training dataset, 50% with upcalls and 50% without, and 1000 for the test set, maintaining the same ratio.\n",
    "\n",
    "Now we need to decide *how* these segments will be represented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section7></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  7. Choosing the spectrogram settings\n",
    "\n",
    "As mentioned earlier, we'll represent the segments as spectrograms.\n",
    "In the .zip file where you found the data, there's also a spectrogram configuration file (```spec_config.json```) which contains the settings we want to use.\n",
    "\n",
    "This configuration file is simply a text file in the ```.json``` format, so you could make a copy of it, change a few parameters and save several settings to use later or to share the with someone else.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_cfg = load_audio_representation('spec_config.json', name=\"spectrogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a python dictionary. We could change some value, like the step size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spec_cfg['step'] = 0.064"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we will stick to the original here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section8></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Creating the database\n",
    "\n",
    "Now we have to compute the spectrograms following the settings above for each selection in our selection tables and then save them in a database.\n",
    "\n",
    "All of this can be done with the ```dbi.create_database``` function in Ketos.\n",
    "\n",
    "We will start with the training dataset. We need to indicate the name for the database we want to create, where the audio files are, a name for the dataset, the selections table and, finally the audio representation. As specified in our ``spec_cfg``, this is a Magnitude spectrogram, but ketos can also create databases with Power, Mel and CQT spectrograms, as well as time-domain data (waveforms).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbi.create_database(output_file='database.h5', data_dir='data/train',\n",
    "                               dataset_name='train',selections=selections_train,\n",
    "                               audio_repres=spec_cfg)\n",
    "                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we do the same thing for the test set. Note that, by specifying the same database name, we are telling ketos that we want to add the test set to the existing database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbi.create_database(output_file='database.h5', data_dir='data/test',\n",
    "                               dataset_name='test',selections=selections_test,\n",
    "                               audio_repres=spec_cfg)\n",
    "                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our database with spectrograms representing audio segments with and without the North Atlantic Right Whale upcall. The data is divided into 'train' and 'test'. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = dbi.open_file(\"database.h5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the data divided into 'train' and 'test' These are called 'groups' in HDF5 terms. Within each of them there's a dataset called 'data', which contains the spectrograms and respective labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close() #close the database connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will likely not need to directly interact with the database. In a following tutorial, we will use Ketos to build a deep neural network and train it to recognize upcalls. Ketos handles the database interactions, so we won't really have to go into the details of it, but if you would like to learn more about how to get data from this database, take a look at the [database_interface](https://docs.meridian.cs.dal.ca/ketos/modules/data_handling/database_interface.html) module in ketos and the [pyTables](https://www.pytables.org/index.html) documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
