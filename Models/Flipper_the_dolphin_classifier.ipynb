{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Flipper_the_dolphin_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoVld9cHOA-e"
      },
      "source": [
        "# Training 'Flipper_06', a binary classifier to detect dolphin sounds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzcQpND4LjWu"
      },
      "source": [
        "In this notebook we will use the database (spectrograms) we previously created in the ```database_creation_pamguard``` notebook to train a Ketos model. This first model is a binary classifier that takes 3 seconds long spectrograms and classify them into 2 classes: 1 (presence of dolphin click trains), or 0 (absence of click trains).\n",
        "\n",
        "We will then use this model on acoustic recordings (.wav files of several minutes) as a detector, to spot trains of dolphin clicks.\n",
        "\n",
        "The content of this notebook partly comes from the Ketos documentations. the comments and code were adpated to our current ClickLearn project. \n",
        "\n",
        "\n",
        "## Contents:\n",
        "\n",
        "[1. Mouting drive, importing the libraries and setting the paths](#section1)  \n",
        "[2. Creating the data feed and the model](#section2)  \n",
        "[3. Creating and training the Neural Network](#section3)  \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiltqJkJOJXL"
      },
      "source": [
        "<a id=\"section1\"></a>\n",
        "##1. Mouting drive, importing the libraries and setting the paths\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH5RJ0UQMVLY"
      },
      "source": [
        "Mounting a google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DkkGu30np6r",
        "outputId": "97e06494-bddb-4c8a-82a5-9beaa2a4efa4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_7vXrzOMdRf"
      },
      "source": [
        "Installing ketos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBgW_RzaroEE",
        "outputId": "7fddb984-5765-43dc-a3e7-ed0f5a958d85"
      },
      "source": [
        "!pip install ketos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ketos\n",
            "  Downloading ketos-2.4.0.tar.gz (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ketos) (1.19.5)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.7/dist-packages (from ketos) (3.4.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ketos) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ketos) (1.1.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from ketos) (57.4.0)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.7/dist-packages (from ketos) (2.7.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from ketos) (1.0.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from ketos) (0.18.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from ketos) (0.8.1)\n",
            "Collecting datetime_glob\n",
            "  Downloading datetime-glob-1.0.8.tar.gz (10 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ketos) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ketos) (4.62.3)\n",
            "Collecting pint\n",
            "  Downloading Pint-0.18-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 34.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ketos) (5.4.8)\n",
            "Collecting version-parser\n",
            "  Downloading version_parser-1.0.1.tar.gz (4.4 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (1.13.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (1.42.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (0.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (3.10.0.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (1.15.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (12.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (0.22.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (3.17.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (2.7.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->ketos) (2.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2->ketos) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2->ketos) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2->ketos) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2->ketos) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2->ketos) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2->ketos) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2->ketos) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2->ketos) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2->ketos) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2->ketos) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2->ketos) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.2->ketos) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.2->ketos) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.2->ketos) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2->ketos) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2->ketos) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2->ketos) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2->ketos) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2->ketos) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.2->ketos) (3.1.1)\n",
            "Collecting lexery>=1.0.0\n",
            "  Downloading lexery-1.1.1.tar.gz (5.4 kB)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->ketos) (1.5.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa->ketos) (21.3)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa->ketos) (1.1.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa->ketos) (0.10.3.post1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->ketos) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa->ketos) (0.51.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->ketos) (2.1.9)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->ketos) (0.2.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->ketos) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa->ketos) (3.0.6)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->ketos) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->ketos) (3.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa->ketos) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->ketos) (2.21)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ketos) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ketos) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ketos) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->ketos) (2018.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ketos) (1.2.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ketos) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ketos) (2.6.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ketos) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ketos) (2.4.1)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.7/dist-packages (from tables->ketos) (2.7.3)\n",
            "Building wheels for collected packages: ketos, datetime-glob, lexery, version-parser\n",
            "  Building wheel for ketos (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ketos: filename=ketos-2.4.0-py3-none-any.whl size=226286 sha256=b50a399580e1247e2bfe4ded44c77f798cadc0ed7ab87425f25a7bd58ab03d37\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/74/ec/07b9dbb748e2c8bd8c2e71833a4ff12edd76f4e6b5864fdbcb\n",
            "  Building wheel for datetime-glob (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for datetime-glob: filename=datetime_glob-1.0.8-py3-none-any.whl size=7980 sha256=a32f85f1b04a5d720d01315e3fa7168fd1c5c2119d086ccfcd2ec63a7ffe2b5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/83/5f/fc21bcb17423bdbb629b5faea89d6307d6fc4b7f4976ded714\n",
            "  Building wheel for lexery (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lexery: filename=lexery-1.1.1-py3-none-any.whl size=4892 sha256=31e7ed8ced41ed4dab7b40dd72595a782ee6cb030c76da3db4f63ebed4165422\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/69/66/3916e07b71430a7628b43521720bc4a9d1a8d34f81843533f7\n",
            "  Building wheel for version-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for version-parser: filename=version_parser-1.0.1-py3-none-any.whl size=4863 sha256=c206bba6befa42ea1bb025dd34665fb3c9bb5662bfe25ad4b9a6193f613fc936\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/c8/34/ef297116752554e212bc4a066f267711e03a7cbb71b5301843\n",
            "Successfully built ketos datetime-glob lexery version-parser\n",
            "Installing collected packages: lexery, version-parser, pint, datetime-glob, ketos\n",
            "Successfully installed datetime-glob-1.0.8 ketos-2.4.0 lexery-1.1.1 pint-0.18 version-parser-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1SVzuqZrvu8",
        "outputId": "1118d70a-0e5e-44f2-d28f-3e054b2a43ed"
      },
      "source": [
        "from ketos.data_handling import selection_table as sl\n",
        "import ketos.data_handling.database_interface as dbi\n",
        "from ketos.data_handling.parsing import load_audio_representation\n",
        "from ketos.audio.spectrogram import MagSpectrogram\n",
        "from ketos.audio.audio_loader import AudioFrameLoader\n",
        "from ketos.data_handling.parsing import load_audio_representation\n",
        "from ketos.neural_networks.resnet import ResNetInterface\n",
        "from ketos.data_handling.data_feeding import BatchGenerator\n",
        "import ketos.neural_networks.dev_utils.detection as det\n",
        "\n",
        "from google.colab import files\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFfVMxzCOwkz"
      },
      "source": [
        "Identifying GPU device and listing:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y834XqluYCcJ",
        "outputId": "73114f39-45b3-401c-f975-2ef239cb9b11"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clj_nDLGYWe1",
        "outputId": "2f0602ca-d961-42d4-c45e-e594f419952e"
      },
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjAGZXZ1MtsP"
      },
      "source": [
        "<a id=\"section2\"></a>\n",
        "## 2. Creating the data feed and the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT5HAxHTMjcP"
      },
      "source": [
        "opening Ketos database (spectrograms)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LrkG2Fnq8ya"
      },
      "source": [
        "db = dbi.open_file(\"gdrive/MyDrive/database_ketos_02.h5\", 'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVrqmxFisZjx",
        "outputId": "4aaddd8a-de4f-4371-917e-c6f72a7b185f"
      },
      "source": [
        "db"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "File(filename=gdrive/MyDrive/database_ketos_02.h5, title='', mode='r', root_uep='/', filters=Filters(complevel=0, shuffle=False, bitshuffle=False, fletcher32=False, least_significant_digit=None))\n",
              "/ (RootGroup) ''\n",
              "/test (Group) ''\n",
              "/test/data (Table(1112,), fletcher32, shuffle, zlib(1)) ''\n",
              "  description := {\n",
              "  \"data\": Float32Col(shape=(86, 8162), dflt=0.0, pos=0),\n",
              "  \"filename\": StringCol(itemsize=100, shape=(), dflt=b'', pos=1),\n",
              "  \"id\": UInt32Col(shape=(), dflt=0, pos=2),\n",
              "  \"label\": UInt8Col(shape=(), dflt=0, pos=3),\n",
              "  \"offset\": Float64Col(shape=(), dflt=0.0, pos=4)}\n",
              "  byteorder := 'little'\n",
              "  chunkshape := (1,)\n",
              "/train (Group) ''\n",
              "/train/data (Table(5455,), fletcher32, shuffle, zlib(1)) ''\n",
              "  description := {\n",
              "  \"data\": Float32Col(shape=(86, 8162), dflt=0.0, pos=0),\n",
              "  \"filename\": StringCol(itemsize=100, shape=(), dflt=b'', pos=1),\n",
              "  \"id\": UInt32Col(shape=(), dflt=0, pos=2),\n",
              "  \"label\": UInt8Col(shape=(), dflt=0, pos=3),\n",
              "  \"offset\": Float64Col(shape=(), dflt=0.0, pos=4)}\n",
              "  byteorder := 'little'\n",
              "  chunkshape := (1,)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p0Qh1VkMw4q"
      },
      "source": [
        "Attributing names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ9k9-wxse-A"
      },
      "source": [
        "# CAUTION: these names should not be changed when using the ketos build because they are unfortunately hard coded as train_data and val_data\n",
        "train_data = dbi.open_table(db, \"/train/data\")\n",
        "val_data = dbi.open_table(db, \"/test/data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D_DgGsAtMR_",
        "outputId": "4c943c99-f267-4b99-ed62-1d6730800565"
      },
      "source": [
        "print(train_data.shape, val_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5455,) (1112,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr5rd04SEl_o",
        "outputId": "6e5087ed-48e7-42dc-b33d-2a582aec73b4"
      },
      "source": [
        "train_data[0][0].shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86, 8162)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Oq6kgX1muY_"
      },
      "source": [
        "Custom function for batch loaders:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F6NubJli9qmg"
      },
      "source": [
        "from skimage.transform import resize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3SdhqLu0cBG"
      },
      "source": [
        "def transform_batch_custom(X, Y):\n",
        "    '''This function reshapes the spectrograms into squares so that the ketos training loop can handle them.'''\n",
        "    temp = resize(X, (X.shape[0], 86, 86))\n",
        "    x = temp.reshape(temp.shape[0],temp.shape[1],temp.shape[2],1)\n",
        "    y = tf.one_hot(Y['label'], depth=2, axis=1).numpy()\n",
        "    return x, y\n",
        "\n",
        "train_generator = BatchGenerator(batch_size=128, data_table=train_data,\n",
        "                                 output_transform_func=transform_batch_custom,\n",
        "                                 shuffle=True, refresh_on_epoch_end=True)\n",
        "\n",
        "val_generator = BatchGenerator(batch_size=128, data_table=val_data,\n",
        "                                output_transform_func=transform_batch_custom,\n",
        "                                shuffle=True, refresh_on_epoch_end=False)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx6BTGfENB82"
      },
      "source": [
        "recipe.json contains the model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Moh45dV5O2sH"
      },
      "source": [
        "resnet = ResNetInterface.build_from_recipe_file(\"gdrive/MyDrive/recipe.json\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F7ranRB8nVr"
      },
      "source": [
        "resnet.train_generator = train_generator\n",
        "resnet.val_generator = val_generator"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA6E-16TNbUX"
      },
      "source": [
        "<a id=\"section3\"></a>\n",
        "## 3. Creating and training the Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46DO_vzqJQLh"
      },
      "source": [
        "### Training attempt #6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY61gD5XKJ8r"
      },
      "source": [
        "resnet.checkpoint_dir = \"gdrive/MyDrive/content/models/checkpoints_flipper06\""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnBlqMgNKKG8",
        "outputId": "7f000c14-dd2f-48bb-9a11-a42f6a5fab8a"
      },
      "source": [
        "#Original settings\n",
        "resnet.early_stopping_monitor"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline': 0.5,\n",
              " 'decreasing': True,\n",
              " 'delta': 0.1,\n",
              " 'max_epochs': None,\n",
              " 'metric': 'val_loss',\n",
              " 'min_epochs': 5,\n",
              " 'period': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJtBtu5IKWEl"
      },
      "source": [
        "#change the early stopping rules to use val_CategoricalAccuracy instead of Val_loss\n",
        "resnet.early_stopping_monitor = {'baseline': None,  #determines if a specific value is aimed at or not \n",
        " 'decreasing': False,        # determines the direction of what we consider as an improvement (increase or decrease) of the metric\n",
        " 'delta': 0.01,              # determines what is an improvement between 2 epochs. Otherwise we consider it is not improving \n",
        " 'max_epochs': None,         # not documented...\n",
        " 'metric': 'val_CategoricalAccuracy',   # the metric we are following for early stopping\n",
        " 'min_epochs': 3,            # The #epoch from which the monitoring starts \n",
        " 'period': 3}                # number of epochs without improvement to stop training "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_azI2TJIKnk-",
        "outputId": "418b28a7-6faa-418e-cd7b-c9b956b2acdc"
      },
      "source": [
        "resnet.early_stopping_monitor"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'baseline': None,\n",
              " 'decreasing': False,\n",
              " 'delta': 0.01,\n",
              " 'max_epochs': None,\n",
              " 'metric': 'val_CategoricalAccuracy',\n",
              " 'min_epochs': 3,\n",
              " 'period': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3Xi3Rr6Ks1d",
        "outputId": "42f216cb-ef77-4f10-b2a8-d7eba1e8cb89"
      },
      "source": [
        "resnet.train_loop(n_epochs=14, verbose=True, checkpoint_freq = 1, early_stopping = True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================\n",
            "Epoch: 1 \n",
            "train_loss: 0.12664449214935303\n",
            "train_CategoricalAccuracy: 0.901 train_Precision: 0.936 train_Recall: 0.862 \n",
            "val_loss: 0.5386421084403992\n",
            "val_CategoricalAccuracy: 0.557 val_Precision: 1.000 val_Recall: 0.092 \n",
            "\n",
            "====================================================================================\n",
            "\n",
            "Focus metric val_CategoricalAccuracy\n",
            "\n",
            "====================================================================================\n",
            "Epoch: 2 \n",
            "train_loss: 0.058505818247795105\n",
            "train_CategoricalAccuracy: 0.954 train_Precision: 0.960 train_Recall: 0.948 \n",
            "val_loss: 0.44273102283477783\n",
            "val_CategoricalAccuracy: 0.535 val_Precision: 1.000 val_Recall: 0.048 \n",
            "\n",
            "====================================================================================\n",
            "\n",
            "Focus metric val_CategoricalAccuracy\n",
            "\n",
            "====================================================================================\n",
            "Epoch: 3 \n",
            "train_loss: 0.037050385028123856\n",
            "train_CategoricalAccuracy: 0.977 train_Precision: 0.969 train_Recall: 0.985 \n",
            "val_loss: 0.4362502992153168\n",
            "val_CategoricalAccuracy: 0.540 val_Precision: 1.000 val_Recall: 0.057 \n",
            "\n",
            "====================================================================================\n",
            "\n",
            "Focus metric val_CategoricalAccuracy\n",
            "\n",
            "====================================================================================\n",
            "Epoch: 4 \n",
            "train_loss: 0.012789016589522362\n",
            "train_CategoricalAccuracy: 0.998 train_Precision: 0.997 train_Recall: 0.999 \n",
            "val_loss: 0.31589895486831665\n",
            "val_CategoricalAccuracy: 0.693 val_Precision: 1.000 val_Recall: 0.372 \n",
            "\n",
            "====================================================================================\n",
            "\n",
            "Focus metric val_CategoricalAccuracy\n",
            "abs: tf.Tensor(0.13669062, shape=(), dtype=float32)\n",
            "\n",
            "Epochs without improvement: 0\n",
            "\n",
            "Current value: tf.Tensor(0.6933453, shape=(), dtype=float32)\n",
            "\n",
            "Best value: tf.Tensor(0.6933453, shape=(), dtype=float32)\n",
            "\n",
            "====================================================================================\n",
            "Epoch: 5 \n",
            "train_loss: 0.010398338548839092\n",
            "train_CategoricalAccuracy: 0.998 train_Precision: 0.998 train_Recall: 0.997 \n",
            "val_loss: 0.2355262041091919\n",
            "val_CategoricalAccuracy: 0.776 val_Precision: 1.000 val_Recall: 0.541 \n",
            "\n",
            "====================================================================================\n",
            "\n",
            "Focus metric val_CategoricalAccuracy\n",
            "abs: tf.Tensor(0.08273381, shape=(), dtype=float32)\n",
            "\n",
            "Epochs without improvement: 0\n",
            "\n",
            "Current value: tf.Tensor(0.7760791, shape=(), dtype=float32)\n",
            "\n",
            "Best value: tf.Tensor(0.7760791, shape=(), dtype=float32)\n",
            "\n",
            "====================================================================================\n",
            "Epoch: 6 \n",
            "train_loss: 0.006525080651044846\n",
            "train_CategoricalAccuracy: 0.999 train_Precision: 0.999 train_Recall: 0.999 \n",
            "val_loss: 0.11854957044124603\n",
            "val_CategoricalAccuracy: 0.894 val_Precision: 1.000 val_Recall: 0.783 \n",
            "\n",
            "====================================================================================\n",
            "\n",
            "Focus metric val_CategoricalAccuracy\n",
            "abs: tf.Tensor(0.11780578, shape=(), dtype=float32)\n",
            "\n",
            "Epochs without improvement: 0\n",
            "\n",
            "Current value: tf.Tensor(0.8938849, shape=(), dtype=float32)\n",
            "\n",
            "Best value: tf.Tensor(0.8938849, shape=(), dtype=float32)\n",
            "\n",
            "====================================================================================\n",
            "Epoch: 7 \n",
            "train_loss: 0.003481643507257104\n",
            "train_CategoricalAccuracy: 1.000 train_Precision: 1.000 train_Recall: 1.000 \n",
            "val_loss: 0.07893414050340652\n",
            "val_CategoricalAccuracy: 0.937 val_Precision: 1.000 val_Recall: 0.871 \n",
            "\n",
            "====================================================================================\n",
            "\n",
            "Focus metric val_CategoricalAccuracy\n",
            "abs: tf.Tensor(0.043165445, shape=(), dtype=float32)\n",
            "\n",
            "Epochs without improvement: 0\n",
            "\n",
            "Current value: tf.Tensor(0.93705034, shape=(), dtype=float32)\n",
            "\n",
            "Best value: tf.Tensor(0.93705034, shape=(), dtype=float32)\n",
            "\n",
            "====================================================================================\n",
            "Epoch: 8 \n",
            "train_loss: 0.0031787981279194355\n",
            "train_CategoricalAccuracy: 1.000 train_Precision: 1.000 train_Recall: 1.000 \n",
            "val_loss: 0.035959869623184204\n",
            "val_CategoricalAccuracy: 0.980 val_Precision: 1.000 val_Recall: 0.959 \n",
            "\n",
            "====================================================================================\n",
            "\n",
            "Focus metric val_CategoricalAccuracy\n",
            "abs: tf.Tensor(0.043165505, shape=(), dtype=float32)\n",
            "\n",
            "Epochs without improvement: 0\n",
            "\n",
            "Current value: tf.Tensor(0.98021585, shape=(), dtype=float32)\n",
            "\n",
            "Best value: tf.Tensor(0.98021585, shape=(), dtype=float32)\n",
            "\n",
            "====================================================================================\n",
            "Epoch: 9 \n",
            "train_loss: 0.0029813137371093035\n",
            "train_CategoricalAccuracy: 1.000 train_Precision: 1.000 train_Recall: 1.000 \n",
            "val_loss: 0.03177231550216675\n",
            "val_CategoricalAccuracy: 0.987 val_Precision: 1.000 val_Recall: 0.972 \n",
            "\n",
            "====================================================================================\n",
            "\n",
            "Focus metric val_CategoricalAccuracy\n",
            "abs: tf.Tensor(0.0062949657, shape=(), dtype=float32)\n",
            "\n",
            "Epochs without improvement: 1\n",
            "\n",
            "Current value: tf.Tensor(0.9865108, shape=(), dtype=float32)\n",
            "\n",
            "Best value: tf.Tensor(0.98021585, shape=(), dtype=float32)\n",
            "\n",
            "====================================================================================\n",
            "Epoch: 10 \n",
            "train_loss: 0.001981868641451001\n",
            "train_CategoricalAccuracy: 1.000 train_Precision: 1.000 train_Recall: 1.000 \n",
            "val_loss: 0.015171423554420471\n",
            "val_CategoricalAccuracy: 0.997 val_Precision: 0.995 val_Recall: 1.000 \n",
            "\n",
            "====================================================================================\n",
            "\n",
            "Focus metric val_CategoricalAccuracy\n",
            "abs: tf.Tensor(0.017086327, shape=(), dtype=float32)\n",
            "\n",
            "Epochs without improvement: 0\n",
            "\n",
            "Current value: tf.Tensor(0.9973022, shape=(), dtype=float32)\n",
            "\n",
            "Best value: tf.Tensor(0.9973022, shape=(), dtype=float32)\n",
            "\n",
            "====================================================================================\n",
            "Epoch: 11 \n",
            "train_loss: 0.0016854291316121817\n",
            "train_CategoricalAccuracy: 1.000 train_Precision: 1.000 train_Recall: 1.000 \n",
            "val_loss: 0.011444717645645142\n",
            "val_CategoricalAccuracy: 0.998 val_Precision: 0.996 val_Recall: 1.000 \n",
            "\n",
            "====================================================================================\n",
            "\n",
            "Focus metric val_CategoricalAccuracy\n",
            "abs: tf.Tensor(0.0008992553, shape=(), dtype=float32)\n",
            "\n",
            "Epochs without improvement: 1\n",
            "\n",
            "Current value: tf.Tensor(0.99820143, shape=(), dtype=float32)\n",
            "\n",
            "Best value: tf.Tensor(0.9973022, shape=(), dtype=float32)\n",
            "\n",
            "====================================================================================\n",
            "Epoch: 12 \n",
            "train_loss: 0.001971317222341895\n",
            "train_CategoricalAccuracy: 1.000 train_Precision: 1.000 train_Recall: 1.000 \n",
            "val_loss: 0.014696076512336731\n",
            "val_CategoricalAccuracy: 0.996 val_Precision: 0.993 val_Recall: 1.000 \n",
            "\n",
            "====================================================================================\n",
            "\n",
            "Focus metric val_CategoricalAccuracy\n",
            "abs: tf.Tensor(0.0008993149, shape=(), dtype=float32)\n",
            "\n",
            "Epochs without improvement: 2\n",
            "\n",
            "Current value: tf.Tensor(0.99640286, shape=(), dtype=float32)\n",
            "\n",
            "Best value: tf.Tensor(0.9973022, shape=(), dtype=float32)\n",
            "\n",
            "====================================================================================\n",
            "Epoch: 13 \n",
            "train_loss: 0.0014494572533294559\n",
            "train_CategoricalAccuracy: 1.000 train_Precision: 1.000 train_Recall: 1.000 \n",
            "val_loss: 0.01396322250366211\n",
            "val_CategoricalAccuracy: 0.996 val_Precision: 0.993 val_Recall: 1.000 \n",
            "\n",
            "====================================================================================\n",
            "\n",
            "Focus metric val_CategoricalAccuracy\n",
            "abs: tf.Tensor(0.0008993149, shape=(), dtype=float32)\n",
            "\n",
            "Epochs without improvement: 3\n",
            "\n",
            "Current value: tf.Tensor(0.99640286, shape=(), dtype=float32)\n",
            "\n",
            "Best value: tf.Tensor(0.9973022, shape=(), dtype=float32)\n",
            "\n",
            "====================================================================================\n",
            "Epoch: 14 \n",
            "train_loss: 0.001444941502995789\n",
            "train_CategoricalAccuracy: 1.000 train_Precision: 1.000 train_Recall: 1.000 \n",
            "val_loss: 0.03000209480524063\n",
            "val_CategoricalAccuracy: 0.981 val_Precision: 0.963 val_Recall: 1.000 \n",
            "\n",
            "====================================================================================\n",
            "\n",
            "Focus metric val_CategoricalAccuracy\n",
            "abs: tf.Tensor(0.016187072, shape=(), dtype=float32)\n",
            "\n",
            "Epochs without improvement: 4\n",
            "\n",
            "Current value: tf.Tensor(0.9811151, shape=(), dtype=float32)\n",
            "\n",
            "Best value: tf.Tensor(0.9973022, shape=(), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'checkpoint_name': 'cp-0010.ckpt'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtGivlgHnkBQ"
      },
      "source": [
        "resnet.save_model('gdrive/MyDrive/content/models/Flipper_06_13epochs.kt',audio_repr_file='/content/gdrive/MyDrive/content/spec_config_spectrogram_01.json')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efL4saf1UkM2"
      },
      "source": [
        "We finally get the index of the last epoch with improvement (early stopping), to be able to find the best model in `resnet`object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo-eThlZTblP",
        "outputId": "899edb49-c48c-4c3f-c486-0e9b6a201f14"
      },
      "source": [
        "resnet.last_epoch_with_improvement"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}